<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Effects of Object Complexity on 3D Virtual Object Observation in Virtual Reality">
  <meta name="keywords" content="">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Augmented Object Intelligence with XR-Objects</title>

  <!-- Global site tag (gtag.js) - Google Analytics -->
  <!-- <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL');
  </script> -->

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>


<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">Effects of Object Complexity in Occlusion, Structure, and Texture on 3D Virtual Object Observation in Virtual Reality</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block">
              <a href="https://shuaikx.github.io/" target="_blank">Kexiang Shuai</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://imyueli.github.io/" target="_blank">Yue Li</a><sup>1</sup>,</span>
            <span class="author-block">
              <a href="https://cma.hkust-gz.edu.cn/faculty-regular/hai-ning-liang/" target="_blank" >Hai-Ning Liang</a><sup>1</sup>,
            </span>
           
          </div>

          <!-- <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup> Google &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <sup>2</sup> Massachusetts Institute of Technology</span>
            <br/>
            <span class="author-block"><sup>2</sup> Massachusetts Institute of Technology</span>
            <br/>
            <span class="author-block"><sup>*</sup>co-senior authorship</span>

            <br/><br/> -->
          <div>
            <span class="author-block"><a href="https://ieeexplore.ieee.org/xpl/conhome/10506842/proceeding" target="_blank" >2023 Asia Conference on Cognitive Engineering and Intelligent Interaction (CEII)</a></span>
            
          </div>

          <div class="column has-text-centered">
            <div class="publication-links">
              <!-- PDF Link. -->
              <span class="link-block">
                <a href="https://ieeexplore.ieee.org/abstract/document/10506895" target="_blank" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                  </span>
                  <span>Paper</span>
                </a>
              </span>
              <!-- Code Link. -->
              <!-- <span class="link-block">
                <a href="https://github.com/google/xr-objects" target="_blank" 
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon">
                      <i class="fab fa-github"></i>
                  </span>
                  <span>Code</span>
                  </a>
              </span> -->
           
            </div>

          </div>
        </div>
      </div>
    </div>
  </div>
</section>

 <!-- Abstract. -->
 <div class="columns is-centered has-text-centered">
  <div class="column is-four-fifths">
    <h2 class="title is-3">Abstract</h2>
    <div class="content has-text-justified">
      <p>
        <span class="dnerf">Virtual Reality</span> (VR) environments involve users in 3D virtual object interactions and manipulation tasks. 
        Many of these are for the purpose of 3D virtual object observation, such as viewing a reconstructed museum artifact in a virtual museum. 
        In this paper, we present a study that investigated the effects of <span>object complexity</span> in occlusion, structure, and texture on 3D <span>virtual object observation</span> in VR. 
        We implemented a direct manipulation technique that allows users to grab, move, rotate, and scale an object for close-up observations. 
        Twenty participants used the technique to manipulate virtual objects of various levels of complexity 
        in occlusion, structure, and texture, to complete observation tasks (search and classify marks). 
        The results showed that among the three dimensions of object complexity, occlusion and texture 
        have significant impacts on usersâ€™ observation task completion time, but structure showed no significant impact. 
        Our work contributes to the understanding of object complexity for 3D object observation in VR environments
        

Seamless integration of physical objects as interactive digital entities remains a challenge for spatial computing. 
        This paper introduces <span class="dnerf">Augmented Object Intelligence</span> (AOI), a novel XR interaction paradigm designed 
        to blur the lines between digital and physical by endowing real-world objects with the ability to interact as if they were digital,
         where every object has the potential to serve as a portal to vast digital functionalities.
        Our approach utilizes object segmentation and classification, combined with the power of Multimodal Large Language Models (MLLMs), 
        to facilitate these interactions.
        We implement the AOI concept in the form of <span class="dnerf">XR-Objects</span>, an open-source prototype system that provides a platform for users to 
        engage with their physical environment in rich and contextually relevant ways.
        This system enables analog objects to not only convey information but also to initiate digital actions, such as querying for 
        details or executing tasks.
        Our contributions are threefold: (1) we define the AOI concept and detail its advantages over traditional AI assistants, 
        (2) detail the <span class="dnerf">XR-Objects</span> system's open-source design and implementation, and 
        (3) show its versatility through a variety of use cases and a user study.
        
      </p>
     
    </div>
  </div>
</div>
<!--/ Abstract. -->



<section class="section">
  <!-- Paper video. -->
  <!-- <div class="columns is-centered has-text-centered">
    <div class="column is-four-fifths" >
      <h2 class="title is-3">Video</h2>
     
        <video id="teaser" autoplay loop playsinline controls height="300px">
          <source src="./static/videos/XR-Objects-UIST24.mp4"
                  type="video/mp4">
        </video>
   
    </div> -->
  </div>
  <!--/ Paper video. -->

</section>


<section class="hero is-light is-small">
  <div class="hero-body">
    <div class="container">
      <div class="columns is-centered">
        <div class="column is-8">
          <div class="content">
            <h2 class="title is-3">Applications</h2>
            <img src="https://github.com/google/xr-objects/raw/main/docs/FigureXRObjects.jpg"
        class="interpolation-image" width="100%"/>
        </div>
            <p> <img  style="float: left;padding-right: 30px;" src="./static/images/applications.png"
              width="225px"/>Through AOI, we envision XR-Objects to be useful across a variety of real-world applications. 
              By enabling in situ digital interactions with non-instrumented analog objects, we can expand their utility 
              (e.g., enabling a pot to double as a cooking timer), better synthesize their relevant information 
              (e.g., comparing nutritional value), and overall enable richer interactivity and flexibility in everyday interactions. 
                Here we present five example application scenarios from a broad application space we envision that highlight the value 
                of XR-Objects.</p><br/>
          </div>
        </div>
      </div>  
    </div>
        
      <br/>
        <div id="results-carousel" class="carousel results-carousel" style="border-width:0px;">
         
          <div class="item item-steve" style="border-width:0px;">
            <div class="columns is-centered" style="border-width:0px;">
            <img poster="" id="steve"  src="./static/images/discover.png"
            width="70%"/>
          </div>
          </div>
          
          <div class="item item-shiba" style="border-width:0px;">
            <div class="columns is-centered" style="border-width:0px;">
              
            <img poster="" id="shiba" src="./static/images/productivity.png"
            width="80%">
          </div>
          </div>
          <div class="item item-chair-tp" style="border-width:0px;">
            <div class="item" style="border-width:0px;">
              <img poster="" id="chair-tp"  src="./static/images/learning.png"
              width="90%">
            </div>
          </div>
          <div class="item item-fullbody" style="border-width:0px;">
            <img poster="" id="fullbody" src="./static/images/IOT.png"
            width="95%">
          </div>      
        </div>
        <br/>
        <h2 class="subtitle has-text-centered">
          <span class="dnerf">XR-Objects</span> makes analog objects interactable as if they were digital.
        </h2>
      
  </div>
 
</div>
</section>


<section class="section">
  
  <div class="container is-max-desktop">
    <!-- Concurrent Work.  -->
    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Implementation</h2>

        <div class="content has-text-justified">
          
          <p>
            XR-Objects  leverages developments in spatial understanding via tools such as  SLAM, 
            available in <a
            href="https://developers.google.com/ar">Google ARCore </a> and 
            <a href="https://developer.apple.com/augmented-reality/arkit">Apple ARKit</a>, 
            and machine learning models for object segmentation and classification (<a href="https://cocodataset.org/COCO">COCO</a> 
            via <a href="https://developers.google.com/mediapipe">MediaPipe</a>), that enable us to implement AR interactions 
            with semantic depth.
            We also integrate a Multimodal Large Language Model (MLLM), 
            <a href="https://deepmind.google/technologies/gemini/">Google Gemini</a>, into our system, 
            which further enhances our ability to automate the recognition of objects and their specific 
            semantic information within XR spaces.  
          </p>
        
          <img poster="" id="fullbody" src="./static/images/pipeline_new.png">
        </div>
      </div>
    </div>
    <!--/ Concurrent Work. -->

  </div>
</section>


<section class="section" id="BibTeX">

  

  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @INPROCEEDINGS{10506895,
        author={Shuai, Kexiang and Li, Yue and Liang, Hai-Ning},
        booktitle={2023 Asia Conference on Cognitive Engineering and Intelligent Interaction (CEII)}, 
        title={Effects of Object Complexity in Occlusion, Structure, and Texture on 3D Virtual Object Observation in Virtual Reality}, 
        year={2023},
        volume={},
        number={},
        pages={24-28},
        keywords={Meters;Three-dimensional displays;Virtual reality;Medical services;Virtual museums;Search problems;Complexity theory;virtual reality;interaction techniques;selection and manipulation;virtual objects},
        doi={10.1109/CEII60565.2023.00013}}      
    </code></pre>
  </div>
</section>


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website is built on top of the original<a
            href="https://github.com/xr-objects/xr-objects.github.io">  XR-Objects, <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 </a> International License.
          </p>
          </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>
